{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Assignment background:\n",
        "\n",
        "Machine Learning Engineers are often in charge of the entire ML Platform, which Data Scientists and Data Analysts will use to build models. This includes the Feature Store. Feature Stores are powerful tools that allow Data Scientists and Data Analysts to share and discover features across Machine Learning Systems. As you have learned during this module, feature engineering can be a daunting task that comprises the lion’s share of ML system development time and can really make or break an ML system. Leveraging a Feature Store allows us to share feature engineering work across different models so we do not have to start from scratch on each new model. Feature Stores also have some additional benefits in providing the latest data for real-time ML systems. Machine Learning Engineers should be familiar with setting up a Feature Store and interacting with a Feature Store."
      ],
      "metadata": {
        "id": "6wiwsUEfagV7"
      },
      "id": "6wiwsUEfagV7"
    },
    {
      "cell_type": "code",
      "source": [
        "# Matt Thompson\n",
        "# Assignment 3.1\n",
        "# AAI 540"
      ],
      "metadata": {
        "id": "1MBxuOpGaVoA"
      },
      "id": "1MBxuOpGaVoA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The first few cells here are about getting the current working directory, getting the data from the two data files, and reading the data."
      ],
      "metadata": {
        "id": "bnUpUnLRatgF"
      },
      "id": "bnUpUnLRatgF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f48c7cd8-bc83-4f7f-9b86-e1a16948310c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-26T08:41:02.110095Z",
          "iopub.status.busy": "2025-09-26T08:41:02.109661Z",
          "iopub.status.idle": "2025-09-26T08:41:02.144243Z",
          "shell.execute_reply": "2025-09-26T08:41:02.141232Z",
          "shell.execute_reply.started": "2025-09-26T08:41:02.110072Z"
        },
        "id": "f48c7cd8-bc83-4f7f-9b86-e1a16948310c",
        "outputId": "9bb54353-72b9-49aa-f7b9-83eb6117e4d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/home/sagemaker-user'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1b8b91a-7582-4b19-adc0-f87181f40318",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-26T08:41:06.053139Z",
          "iopub.status.busy": "2025-09-26T08:41:06.052856Z",
          "iopub.status.idle": "2025-09-26T08:41:06.226439Z",
          "shell.execute_reply": "2025-09-26T08:41:06.225334Z",
          "shell.execute_reply.started": "2025-09-26T08:41:06.053118Z"
        },
        "id": "e1b8b91a-7582-4b19-adc0-f87181f40318",
        "outputId": "d6d86f02-eb4d-4656-9dee-6c4c2d00b381"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Untitled.ipynb  Untitled1.ipynb  \u001b[0m\u001b[01;34maai-540-labs\u001b[0m/  \u001b[01;36muser-default-efs\u001b[0m@\n"
          ]
        }
      ],
      "source": [
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a260324c-7ce4-4f69-a641-349acb97840e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-26T08:41:09.050648Z",
          "iopub.status.busy": "2025-09-26T08:41:09.050321Z",
          "iopub.status.idle": "2025-09-26T08:41:10.142767Z",
          "shell.execute_reply": "2025-09-26T08:41:10.141670Z",
          "shell.execute_reply.started": "2025-09-26T08:41:09.050624Z"
        },
        "id": "a260324c-7ce4-4f69-a641-349acb97840e",
        "outputId": "f7ae20b3-5a69-42e9-ba75-da4b34e868c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AWS and SageMaker session established.\n",
            "\n",
            "Loading raw data files from: ./aai-540-labs/lab-3-1-sagemaker-feature-store/...\n",
            "Data files loaded successfully.\n",
            "\n",
            "--- housing.csv Head ---\n",
            "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
            "0    -122.23     37.88                41.0        880.0           129.0   \n",
            "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
            "2    -122.24     37.85                52.0       1467.0           190.0   \n",
            "3    -122.25     37.85                52.0       1274.0           235.0   \n",
            "4    -122.25     37.85                52.0       1627.0           280.0   \n",
            "\n",
            "   population  households  median_income  median_house_value ocean_proximity  \n",
            "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
            "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
            "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
            "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
            "4       565.0       259.0         3.8462            342200.0        NEAR BAY  \n",
            "\n",
            "--- maps.csv Head ---\n",
            "  street_number                   route locality-political  \\\n",
            "0          3130  Grizzly Peak Boulevard           Berkeley   \n",
            "1          2005             Tunnel Road            Oakland   \n",
            "2          6886             Chabot Road            Oakland   \n",
            "3          6365           Florio Street            Oakland   \n",
            "4          5407           Bryant Avenue            Oakland   \n",
            "\n",
            "  administrative_area_level_2-political administrative_area_level_1-political  \\\n",
            "0                        Alameda County                            California   \n",
            "1                        Alameda County                            California   \n",
            "2                        Alameda County                            California   \n",
            "3                        Alameda County                            California   \n",
            "4                        Alameda County                            California   \n",
            "\n",
            "  country-political  postal_code  \\\n",
            "0     United States      94705.0   \n",
            "1     United States      94611.0   \n",
            "2     United States      94618.0   \n",
            "3     United States      94618.0   \n",
            "4     United States      94618.0   \n",
            "\n",
            "                                           address  longitude  latitude  ...  \\\n",
            "0  3130 Grizzly Peak Blvd, Berkeley, CA 94705, USA    -122.23     37.88  ...   \n",
            "1           2005 Tunnel Rd, Oakland, CA 94611, USA    -122.22     37.86  ...   \n",
            "2           6886 Chabot Rd, Oakland, CA 94618, USA    -122.24     37.85  ...   \n",
            "3           6365 Florio St, Oakland, CA 94618, USA    -122.25     37.85  ...   \n",
            "4          5407 Bryant Ave, Oakland, CA 94618, USA    -122.25     37.84  ...   \n",
            "\n",
            "  establishment-natural_feature  airport-establishment-point_of_interest  \\\n",
            "0                           NaN                                      NaN   \n",
            "1                           NaN                                      NaN   \n",
            "2                           NaN                                      NaN   \n",
            "3                           NaN                                      NaN   \n",
            "4                           NaN                                      NaN   \n",
            "\n",
            "  political-sublocality-sublocality_level_1  \\\n",
            "0                                       NaN   \n",
            "1                                       NaN   \n",
            "2                                       NaN   \n",
            "3                                       NaN   \n",
            "4                                       NaN   \n",
            "\n",
            "  administrative_area_level_3-political post_box  \\\n",
            "0                                   NaN      NaN   \n",
            "1                                   NaN      NaN   \n",
            "2                                   NaN      NaN   \n",
            "3                                   NaN      NaN   \n",
            "4                                   NaN      NaN   \n",
            "\n",
            "  establishment-light_rail_station-point_of_interest-transit_station  \\\n",
            "0                                                NaN                   \n",
            "1                                                NaN                   \n",
            "2                                                NaN                   \n",
            "3                                                NaN                   \n",
            "4                                                NaN                   \n",
            "\n",
            "  establishment-point_of_interest  \\\n",
            "0                             NaN   \n",
            "1                             NaN   \n",
            "2                             NaN   \n",
            "3                             NaN   \n",
            "4                             NaN   \n",
            "\n",
            "  aquarium-establishment-park-point_of_interest-tourist_attraction-zoo  \\\n",
            "0                                                NaN                     \n",
            "1                                                NaN                     \n",
            "2                                                NaN                     \n",
            "3                                                NaN                     \n",
            "4                                                NaN                     \n",
            "\n",
            "  campground-establishment-lodging-park-point_of_interest-rv_park-tourist_attraction  \\\n",
            "0                                                NaN                                   \n",
            "1                                                NaN                                   \n",
            "2                                                NaN                                   \n",
            "3                                                NaN                                   \n",
            "4                                                NaN                                   \n",
            "\n",
            "  cemetery-establishment-park-point_of_interest  \n",
            "0                                           NaN  \n",
            "1                                           NaN  \n",
            "2                                           NaN  \n",
            "3                                           NaN  \n",
            "4                                           NaN  \n",
            "\n",
            "[5 rows x 30 columns]\n"
          ]
        }
      ],
      "source": [
        "# Let's try to read the data in from the two data files\n",
        "\n",
        "import pandas as pd\n",
        "import time\n",
        "import os\n",
        "from sagemaker.session import Session\n",
        "from sagemaker.feature_store.feature_group import FeatureGroup\n",
        "from sagemaker import get_execution_role\n",
        "\n",
        "# Define the subdirectory path\n",
        "DATA_PATH = './aai-540-labs/lab-3-1-sagemaker-feature-store/'\n",
        "\n",
        "# This setup is important for creating the Feature Group later.\n",
        "sagemaker_session = Session()\n",
        "region = sagemaker_session.boto_region_name\n",
        "default_bucket = sagemaker_session.default_bucket()\n",
        "prefix = 'featurestore-neighborhood-data'\n",
        "s3_uri = f's3://{default_bucket}/{prefix}'\n",
        "print(\"AWS and SageMaker session established.\")\n",
        "\n",
        "# Load the data\n",
        "print(f\"\\nLoading raw data files from: {DATA_PATH}...\")\n",
        "try:\n",
        "    housing_filepath = os.path.join(DATA_PATH, 'housing.csv')\n",
        "    maps_filepath = os.path.join(DATA_PATH, 'maps.csv')\n",
        "\n",
        "    housing_df = pd.read_csv(housing_filepath)\n",
        "    maps_df = pd.read_csv(maps_filepath)\n",
        "    print(\"Data files loaded successfully.\")\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error: One or both files not found. Please ensure the path is correct and the files exist:\")\n",
        "    print(f\"  Housing file expected at: {housing_filepath}\")\n",
        "    print(f\"  Maps file expected at: {maps_filepath}\")\n",
        "    print(f\"Details: {e}\")\n",
        "    # Empty dataframes if error\n",
        "    housing_df = pd.DataFrame()\n",
        "    maps_df = pd.DataFrame()\n",
        "\n",
        "# Print DataFrames Head\n",
        "print(\"\\n--- housing.csv Head ---\")\n",
        "if not housing_df.empty:\n",
        "    print(housing_df.head())\n",
        "else:\n",
        "    print(\"Dataframe is empty due to loading error.\")\n",
        "\n",
        "print(\"\\n--- maps.csv Head ---\")\n",
        "if not maps_df.empty:\n",
        "    print(maps_df.head())\n",
        "else:\n",
        "    print(\"Dataframe is empty due to loading error.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now that we have the data, print out the column names as we will need these later"
      ],
      "metadata": {
        "id": "rSXGYYv8bz2l"
      },
      "id": "rSXGYYv8bz2l"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd8d9568-c0a0-46d2-915e-a1f34f73f4bb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-26T08:41:18.100083Z",
          "iopub.status.busy": "2025-09-26T08:41:18.099753Z",
          "iopub.status.idle": "2025-09-26T08:41:18.104319Z",
          "shell.execute_reply": "2025-09-26T08:41:18.103606Z",
          "shell.execute_reply.started": "2025-09-26T08:41:18.100061Z"
        },
        "id": "bd8d9568-c0a0-46d2-915e-a1f34f73f4bb",
        "outputId": "836b5bb6-0086-4b0c-c748-3ab2d2ce79be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- housing.csv Columns ---\n",
            "['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income', 'median_house_value', 'ocean_proximity']\n",
            "\n",
            "--- maps.csv Columns ---\n",
            "['street_number', 'route', 'locality-political', 'administrative_area_level_2-political', 'administrative_area_level_1-political', 'country-political', 'postal_code', 'address', 'longitude', 'latitude', 'neighborhood-political', 'postal_code_suffix', 'establishment-point_of_interest-transit_station', 'establishment-park-point_of_interest', 'premise', 'establishment-point_of_interest-subway_station-transit_station', 'airport-establishment-finance-moving_company-point_of_interest-storage', 'subpremise', 'bus_station-establishment-point_of_interest-transit_station', 'establishment-park-point_of_interest-tourist_attraction', 'establishment-natural_feature', 'airport-establishment-point_of_interest', 'political-sublocality-sublocality_level_1', 'administrative_area_level_3-political', 'post_box', 'establishment-light_rail_station-point_of_interest-transit_station', 'establishment-point_of_interest', 'aquarium-establishment-park-point_of_interest-tourist_attraction-zoo', 'campground-establishment-lodging-park-point_of_interest-rv_park-tourist_attraction', 'cemetery-establishment-park-point_of_interest']\n"
          ]
        }
      ],
      "source": [
        "# Let's print out the columns names\n",
        "\n",
        "print(\"--- housing.csv Columns ---\")\n",
        "# Check if DataFrame is not empty before printing columns\n",
        "if not housing_df.empty:\n",
        "    print(housing_df.columns.tolist())\n",
        "else:\n",
        "    print(\"housing_df is empty. Please re-check the file path and loading process.\")\n",
        "\n",
        "print(\"\\n--- maps.csv Columns ---\")\n",
        "if not maps_df.empty:\n",
        "    print(maps_df.columns.tolist())\n",
        "else:\n",
        "    print(\"maps_df is empty. Please re-check the file path and loading process.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f21f53d2-57d7-4dbf-b628-64ff62b0192b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-26T08:49:20.833727Z",
          "iopub.status.busy": "2025-09-26T08:49:20.833452Z",
          "iopub.status.idle": "2025-09-26T08:49:20.937157Z",
          "shell.execute_reply": "2025-09-26T08:49:20.936153Z",
          "shell.execute_reply.started": "2025-09-26T08:49:20.833706Z"
        },
        "id": "f21f53d2-57d7-4dbf-b628-64ff62b0192b",
        "outputId": "4577763f-0455-4fd4-f51a-dde2885e5edf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Step 2 (Feature Engineering) Complete. Final DataFrame Head:\n",
            "                      primary_key  median_house_value  median_house_age  \\\n",
            "0                        28 Palms       222200.000000              20.0   \n",
            "1                Acorn Industrial        81300.000000              50.0   \n",
            "2                      Adams Hill       250733.333333              35.0   \n",
            "3  Agua Mansa Industrial Corridor       112300.000000              10.0   \n",
            "4                        Al Tahoe       109180.000000              20.0   \n",
            "\n",
            "   total_households  bedrooms_per_household  ocean_lt_1h  inland  island  \\\n",
            "0               923                1.017335          1.0     0.0     0.0   \n",
            "1               147                1.659864          0.0     0.0     0.0   \n",
            "2               494                1.034649          1.0     0.0     0.0   \n",
            "3               516                1.102713          0.0     1.0     0.0   \n",
            "4               249                1.641739          0.0     1.0     0.0   \n",
            "\n",
            "   ocean_near_bay  ocean_near_ocean    event_time  \n",
            "0             0.0               0.0  1.758877e+09  \n",
            "1             1.0               0.0  1.758877e+09  \n",
            "2             0.0               0.0  1.758877e+09  \n",
            "3             0.0               0.0  1.758877e+09  \n",
            "4             0.0               0.0  1.758877e+09  \n",
            "\n",
            "Final Feature Group Schema (Names and Types):\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1306 entries, 0 to 1305\n",
            "Data columns (total 11 columns):\n",
            " #   Column                  Non-Null Count  Dtype  \n",
            "---  ------                  --------------  -----  \n",
            " 0   primary_key             1306 non-null   object \n",
            " 1   median_house_value      1306 non-null   float64\n",
            " 2   median_house_age        1306 non-null   float64\n",
            " 3   total_households        1306 non-null   int64  \n",
            " 4   bedrooms_per_household  1300 non-null   float64\n",
            " 5   ocean_lt_1h             1306 non-null   float64\n",
            " 6   inland                  1306 non-null   float64\n",
            " 7   island                  1306 non-null   float64\n",
            " 8   ocean_near_bay          1306 non-null   float64\n",
            " 9   ocean_near_ocean        1306 non-null   float64\n",
            " 10  event_time              1306 non-null   float64\n",
            "dtypes: float64(9), int64(1), object(1)\n",
            "memory usage: 112.4+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Let's try some feature engineering and data preparation\n",
        "#  Begin step 2\n",
        "\n",
        "import pandas as pd\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "# These are the required feature names for the Feature Group\n",
        "RECORD_IDENTIFIER_FEATURE_NAME = 'primary_key'\n",
        "EVENT_TIME_FEATURE_NAME = 'event_time'\n",
        "\n",
        "# Try to Create Common Geographical Key for Joining\n",
        "# Round coordinates (to 3 decimal places) to create common key\n",
        "maps_df['Geo_Join_Key'] = maps_df['latitude'].round(3).astype(str) + '_' + maps_df['longitude'].round(3).astype(str)\n",
        "housing_df['Geo_Join_Key'] = housing_df['latitude'].round(3).astype(str) + '_' + housing_df['longitude'].round(3).astype(str)\n",
        "\n",
        "# Select map keys and drop duplicates for unique neighborhood name\n",
        "map_keys = maps_df[['Geo_Join_Key', 'neighborhood-political']].dropna(subset=['neighborhood-political']).drop_duplicates(subset=['Geo_Join_Key'])\n",
        "\n",
        "\n",
        "# Join DataFrames to associate houses with a neighborhood\n",
        "merged_df = pd.merge(\n",
        "    housing_df,\n",
        "    map_keys,\n",
        "    on='Geo_Join_Key',\n",
        "    how='left'\n",
        ").dropna(subset=['neighborhood-political'])\n",
        "\n",
        "# Limit 'median_house_value' at $500,000\n",
        "merged_df['capped_median_house_value'] = merged_df['median_house_value'].clip(upper=500000)\n",
        "\n",
        "# Need to create discrete 'housing_median_age' (0-9, 10-19, etc.)\n",
        "merged_df['discretized_median_house_age'] = (merged_df['housing_median_age'] // 10) * 10\n",
        "\n",
        "# Calculate 'bedrooms per household' ratio\n",
        "merged_df['bedrooms_per_household'] = merged_df['total_bedrooms'] / merged_df['households']\n",
        "\n",
        "# One-Hot Encode 'ocean_proximity'\n",
        "# Mak sure all 5 required categories exist, filling missing with 0 to prevent errors\n",
        "required_ocean_categories = ['<1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN']\n",
        "ohe_df = pd.get_dummies(merged_df['ocean_proximity'], prefix='', prefix_sep='').astype(int)\n",
        "ohe_df = ohe_df.reindex(columns=required_ocean_categories, fill_value=0)\n",
        "\n",
        "merged_df = pd.concat([merged_df, ohe_df], axis=1)\n",
        "\n",
        "# Aggregate up to the Neighborhood Level\n",
        "# Group by the primary key: 'neighborhood-political'\n",
        "neighborhood_df = merged_df('neighborhood-political').agg(\n",
        "\n",
        "    # Median house value (capped & averaged)\n",
        "    median_house_value=('capped_median_house_value', 'mean'),\n",
        "\n",
        "    # Median house age (discretized & averaged)\n",
        "    median_house_age=('discretized_median_house_age', 'mean'),\n",
        "\n",
        "    # Total households (averaged)\n",
        "    total_households=('households', 'mean'),\n",
        "\n",
        "    # Bedrooms per household (averaged)\n",
        "    bedrooms_per_household=('bedrooms_per_household', 'mean'),\n",
        "\n",
        "    # One-Hot Encoded proportions (averaged OHE columns)\n",
        "    ocean_lt_1h_prop=('<1H OCEAN', 'mean'),\n",
        "    ocean_inland_prop=('INLAND', 'mean'),\n",
        "    ocean_island_prop=('ISLAND', 'mean'),\n",
        "    ocean_near_bay_prop=('NEAR BAY', 'mean'),\n",
        "    ocean_near_ocean_prop=('NEAR OCEAN', 'mean')\n",
        ").reset_index()\n",
        "\n",
        "# Final Data Cleaning and Feature Store Setup\n",
        "\n",
        "# Rename Primary Key column\n",
        "neighborhood_df.rename(columns={'neighborhood-political': RECORD_IDENTIFIER_FEATURE_NAME}, inplace=True)\n",
        "\n",
        "# Round 'total_households' up to the nearest whole number\n",
        "neighborhood_df['total_households'] = np.ceil(neighborhood_df['total_households']).astype(int)\n",
        "\n",
        "# Rename One-Hot Encoded columns to final names\n",
        "# Needed to replace spaces and special characters with underscores/standard characters (this caused errors initially)\n",
        "neighborhood_df.rename(columns={\n",
        "    'ocean_lt_1h_prop': 'ocean_lt_1h',\n",
        "    'ocean_inland_prop': 'inland',\n",
        "    'ocean_island_prop': 'island',\n",
        "    'ocean_near_bay_prop': 'ocean_near_bay',\n",
        "    'ocean_near_ocean_prop': 'ocean_near_ocean'\n",
        "}, inplace=True)\n",
        "\n",
        "# Add Event Time\n",
        "current_time_sec = int(round(time.time()))\n",
        "neighborhood_df[EVENT_TIME_FEATURE_NAME] = pd.Series([current_time_sec] * len(neighborhood_df), dtype=\"float64\")\n",
        "\n",
        "# Print to verify\n",
        "print(\"✅ Step 2 (Feature Engineering) Complete. Final DataFrame Head:\")\n",
        "print(neighborhood_df.head())\n",
        "print(\"\\nFinal Feature Group Schema (Names and Types):\")\n",
        "print(neighborhood_df.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2574be23-f445-48e8-a7ce-45f9ac29248b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-26T08:51:59.009803Z",
          "iopub.status.busy": "2025-09-26T08:51:59.009528Z",
          "iopub.status.idle": "2025-09-26T08:51:59.941108Z",
          "shell.execute_reply": "2025-09-26T08:51:59.940339Z",
          "shell.execute_reply.started": "2025-09-26T08:51:59.009783Z"
        },
        "id": "2574be23-f445-48e8-a7ce-45f9ac29248b",
        "outputId": "9c79fff0-cdda-4ee0-ccf9-589acf88b8b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Feature Definitions inferred for compliant-neighborhood-fg-20250926085159:\n",
            "  - primary_key: String\n",
            "  - median_house_value: Fractional\n",
            "  - median_house_age: Fractional\n",
            "  - total_households: Integral\n",
            "  - bedrooms_per_household: Fractional\n",
            "  - ocean_lt_1h: Fractional\n",
            "  - inland: Fractional\n",
            "  - island: Fractional\n",
            "  - ocean_near_bay: Fractional\n",
            "  - ocean_near_ocean: Fractional\n",
            "  - event_time: Fractional\n",
            "\n",
            "Creating Feature Group: compliant-neighborhood-fg-20250926085159...\n",
            "Waiting for Feature Group to be Created (up to 10 minutes)...\n",
            "❌ Feature Group creation failed or timed out. Status: Creating\n",
            "Please run the manual polling code from our previous attempts to confirm status and proceed.\n"
          ]
        }
      ],
      "source": [
        "# Instantiate and create feature group\n",
        "# Step 3 for this\n",
        "\n",
        "from sagemaker.feature_store.feature_group import FeatureGroup\n",
        "import time\n",
        "\n",
        "# Define variables\n",
        "# Duplicate to enable debugging of this cell\n",
        "RECORD_IDENTIFIER_FEATURE_NAME = 'primary_key'\n",
        "EVENT_TIME_FEATURE_NAME = 'event_time'\n",
        "\n",
        "# Define unique, compliant name for the new Feature Group\n",
        "FEATURE_GROUP_NAME = 'compliant-neighborhood-fg-' + time.strftime('%Y%m%d%H%M%S', time.gmtime())\n",
        "\n",
        "# Instantiate feature group\n",
        "neighborhood_feature_group = FeatureGroup(\n",
        "    name=FEATURE_GROUP_NAME,\n",
        "    sagemaker_session=sagemaker_session\n",
        ")\n",
        "\n",
        "# Load Feature Definitions (Schema Inference)\n",
        "neighborhood_feature_group.load_feature_definitions(data_frame=neighborhood_df)\n",
        "\n",
        "print(f\"\\nFeature Definitions inferred for {FEATURE_GROUP_NAME}:\")\n",
        "for feature in neighborhood_feature_group.feature_definitions:\n",
        "    print(f\"  - {feature.feature_name}: {feature.feature_type.value}\")\n",
        "\n",
        "# Create the Feature Group in AWS\n",
        "print(f\"\\nCreating Feature Group: {FEATURE_GROUP_NAME}...\")\n",
        "\n",
        "neighborhood_feature_group.create(\n",
        "    s3_uri=s3_uri,\n",
        "    record_identifier_name=RECORD_IDENTIFIER_FEATURE_NAME, # 'primary_key'\n",
        "    event_time_feature_name=EVENT_TIME_FEATURE_NAME,       # 'event_time'\n",
        "    role_arn=role,\n",
        "    enable_online_store=True\n",
        ")\n",
        "\n",
        "# Wait for rceation to complete\n",
        "print(\"Waiting for Feature Group to be Created (up to 10 minutes)...\")\n",
        "try:\n",
        "    # Use the SDK's built-in wait capability\n",
        "    neighborhood_feature_group.wait_for_feature_group_creation_complete(timeout=600)\n",
        "    status = neighborhood_feature_group.describe().get('FeatureGroupStatus')\n",
        "    print(f\"✅ Feature Group Status: {status}\")\n",
        "except Exception as e:\n",
        "    # If the wait times out, provide status check instruction\n",
        "    current_status = neighborhood_feature_group.describe().get('FeatureGroupStatus')\n",
        "    print(f\"❌ Feature Group creation failed or timed out. Status: {current_status}\")\n",
        "    print(\"Please run the manual polling code from our previous attempts to confirm status and proceed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wanted to create a polling feature for the feature group creation process"
      ],
      "metadata": {
        "id": "VMpCyzgLe2lC"
      },
      "id": "VMpCyzgLe2lC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f397097-dd69-40bb-92c0-383ae0c7ca4b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-26T08:53:01.309607Z",
          "iopub.status.busy": "2025-09-26T08:53:01.309195Z",
          "iopub.status.idle": "2025-09-26T08:53:01.467308Z",
          "shell.execute_reply": "2025-09-26T08:53:01.465727Z",
          "shell.execute_reply.started": "2025-09-26T08:53:01.309562Z"
        },
        "id": "3f397097-dd69-40bb-92c0-383ae0c7ca4b",
        "outputId": "e54e18a2-80da-488e-e8f3-260dfd83f9fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Polling status for Feature Group: compliant-neighborhood-fg-20250926085159...\n",
            "✅ Feature Group Status: Created (Ready to ingest data!)\n"
          ]
        }
      ],
      "source": [
        "# Poll feature\n",
        "# Used Gemini for help here\n",
        "\n",
        "import time\n",
        "\n",
        "def wait_for_feature_group_creation(feature_group, timeout_minutes=15):\n",
        "    \"\"\"Polls the Feature Group status until it's Created or CreateFailed.\"\"\"\n",
        "    start_time = time.time()\n",
        "    timeout_seconds = timeout_minutes * 60\n",
        "\n",
        "    print(f\"Polling status for Feature Group: {feature_group.name}...\")\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            # Use the describe() method to get the current status from AWS\n",
        "            description = feature_group.describe()\n",
        "            status = description.get('FeatureGroupStatus')\n",
        "        except Exception as e:\n",
        "            # Handle transient connection issues or other AWS errors - definitely needed help with this\n",
        "            print(f\"Error describing Feature Group: {e}. Retrying...\")\n",
        "            status = 'Creating'\n",
        "\n",
        "        if status == 'Created':\n",
        "            print(f\"✅ Feature Group Status: {status} (Ready to ingest data!)\")\n",
        "            break\n",
        "        elif status in ('CreateFailed', 'Deleting', 'DeleteFailed'):\n",
        "            print(f\"❌ Feature Group Status: {status}.\")\n",
        "            print(f\"Failure reason: {description.get('FailureReason')}\")\n",
        "            raise Exception(f\"Feature Group creation failed with status: {status}\")\n",
        "\n",
        "        elapsed_time = time.time() - start_time\n",
        "        if elapsed_time > timeout_seconds:\n",
        "            print(f\"❌ Timed out after {timeout_minutes} minutes. Current Status: {status}.\")\n",
        "            print(\"The resource might still be provisioning; please check the SageMaker Feature Store console.\")\n",
        "            break\n",
        "\n",
        "        print(f\"Status: {status}... Waiting (Elapsed time: {int(elapsed_time)}s)\")\n",
        "        time.sleep(30) # Wait 30 seconds before checking again\n",
        "\n",
        "# Execute polling\n",
        "try:\n",
        "    wait_for_feature_group_creation(neighborhood_feature_group)\n",
        "except Exception as e:\n",
        "    print(e)\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Once the polling function says tehe feature group has been successfully created, we can proceed to ingest the data into the feature group"
      ],
      "metadata": {
        "id": "yQDk0P1dfZmF"
      },
      "id": "yQDk0P1dfZmF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e28c8aaa-30ef-4f43-b8c3-74cbb5fc5440",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-26T08:54:15.045802Z",
          "iopub.status.busy": "2025-09-26T08:54:15.045457Z",
          "iopub.status.idle": "2025-09-26T08:54:21.269554Z",
          "shell.execute_reply": "2025-09-26T08:54:21.268572Z",
          "shell.execute_reply.started": "2025-09-26T08:54:15.045775Z"
        },
        "id": "e28c8aaa-30ef-4f43-b8c3-74cbb5fc5440",
        "outputId": "add8a692-a090-4e1a-e5d6-17fbc23e9d28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Ingesting data from neighborhood_df into the Feature Group...\n",
            "\n",
            "Attempting alternative status check...\n",
            "✅ Data Ingestion Status: Completed (No exception raised during wait=True).\n",
            "Assuming all records were ingested successfully.\n",
            "\n",
            "Verifying a record using the Online Store (GetRecord API):\n",
            "✅ Record for Key '28 Palms' retrieved successfully.\n",
            "Data ingestion confirmed!\n"
          ]
        }
      ],
      "source": [
        "# Let's ingest the data into the feature group\n",
        "# Step 4\n",
        "\n",
        "# Duplicative to enable debugging of the cell independently\n",
        "RECORD_IDENTIFIER_FEATURE_NAME = 'primary_key'\n",
        "EVENT_TIME_FEATURE_NAME = 'event_time'\n",
        "\n",
        "\n",
        "print(\"\\nIngesting data from neighborhood_df into the Feature Group...\")\n",
        "\n",
        "# Ingest the DataFrame into the Feature Group.\n",
        "ingestion_manager = neighborhood_feature_group.ingest(\n",
        "    data_frame=neighborhood_df,\n",
        "    max_workers=3,\n",
        "    wait=True\n",
        ")\n",
        "\n",
        "# Check ingestion status\n",
        "try:\n",
        "    # Attempt the this check first (seems there can be different versions)\n",
        "    failed_rows = ingestion_manager.get_failed_rows()\n",
        "    if failed_rows:\n",
        "        print(f\"\\n❌ Data Ingestion FAILED. Failed Rows Count: {len(failed_rows)}. First failed row:\")\n",
        "        print(failed_rows[:1])\n",
        "    else:\n",
        "        print(\"\\n✅ Data Ingestion Status: Completed\")\n",
        "        print(\"All records ingested successfully into the Online and Offline Stores!\")\n",
        "\n",
        "except AttributeError:\n",
        "    # Try older SDK versions where get_failed_rows() is missing\n",
        "    print(\"\\nAttempting alternative status check...\")\n",
        "    try:\n",
        "        if ingestion_manager._async_result.successful():\n",
        "            print(\"✅ Data Ingestion Status: Completed (No exception raised during wait=True).\")\n",
        "            print(\"Assuming all records were ingested successfully.\")\n",
        "        else:\n",
        "            print(\"❌ Data Ingestion FAILED (Internal error detected). Check CloudWatch logs.\")\n",
        "    except AttributeError:\n",
        "        # Final try, rely on the 'wait=True' completion\n",
        "        print(\"✅ Data Ingestion Status: Completed (Wait finished without error).\")\n",
        "        print(\"Assuming all records were ingested successfully.\")\n",
        "\n",
        "\n",
        "# Verification step\n",
        "print(\"\\nVerifying a record using the Online Store (GetRecord API):\")\n",
        "try:\n",
        "    sagemaker_runtime_client = sagemaker_session.boto_session.client('sagemaker-featurestore-runtime', region_name=region)\n",
        "\n",
        "    # Get the value of the first record identifier from the DataFrame\n",
        "    record_id_value = str(neighborhood_df.iloc[0][RECORD_IDENTIFIER_FEATURE_NAME])\n",
        "\n",
        "    response = sagemaker_runtime_client.get_record(\n",
        "        FeatureGroupName=neighborhood_feature_group.name,\n",
        "        RecordIdentifierValueAsString=record_id_value\n",
        "    )\n",
        "\n",
        "    if response.get('Record'):\n",
        "        print(f\"✅ Record for Key '{record_id_value}' retrieved successfully.\")\n",
        "        print(\"Data ingestion confirmed!\")\n",
        "    else:\n",
        "         print(\"❌ Verification FAILED. Record not found in the Online Store.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"Verification FAILED. Could not retrieve record.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# With the feature store built and now loaded with data, we should be able to run the queries called out in the assignment.\n",
        "\n"
      ],
      "metadata": {
        "id": "NjTC_A5ug2lu"
      },
      "id": "NjTC_A5ug2lu"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "36b04398-5696-454a-80ed-e4a18345e031",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-26T09:03:11.549395Z",
          "iopub.status.busy": "2025-09-26T09:03:11.549006Z",
          "iopub.status.idle": "2025-09-26T09:03:11.665984Z",
          "shell.execute_reply": "2025-09-26T09:03:11.665119Z",
          "shell.execute_reply.started": "2025-09-26T09:03:11.549370Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "36b04398-5696-454a-80ed-e4a18345e031",
        "outputId": "f44849e9-8a93-4111-f92c-db883e6b0690"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'sagemaker_session' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-147888933.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msagemaker_runtime_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboto_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sagemaker-featurestore-runtime'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregion_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mFEATURE_GROUP_NAME\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneighborhood_feature_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mRECORD_IDENTIFIER_FEATURE_NAME\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'primary_key'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'sagemaker_session' is not defined"
          ]
        }
      ],
      "source": [
        "# Query 1\n",
        "# Query Brooktree\n",
        "\n",
        "# These are each duplicative to allow for debugging separately\n",
        "\n",
        "import time\n",
        "\n",
        "sagemaker_runtime_client = sagemaker_session.boto_session.client('sagemaker-featurestore-runtime', region_name=region)\n",
        "FEATURE_GROUP_NAME = neighborhood_feature_group.name\n",
        "RECORD_IDENTIFIER_FEATURE_NAME = 'primary_key'\n",
        "query_key = \"Brooktree\"\n",
        "\n",
        "print(f\"--- Query 1: Get Real-Time Record for primary_key = '{query_key}' ---\")\n",
        "\n",
        "response = sagemaker_runtime_client.get_record(\n",
        "    FeatureGroupName=FEATURE_GROUP_NAME,\n",
        "    RecordIdentifierValueAsString=query_key\n",
        ")\n",
        "\n",
        "record = response.get('Record')\n",
        "if record:\n",
        "    print(\"\\n✅ Query Successful! Retrieved Features:\")\n",
        "    for feature in record:\n",
        "        print(f\"  - {feature['FeatureName']}: {feature['ValueAsString']}\")\n",
        "else:\n",
        "    print(f\"❌ Query Failed: Record for '{query_key}' not found. (Check if the key was present in the aggregated data.)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f30684a-0369-4ac6-ba5f-f8cd2246e532",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-26T09:06:05.106713Z",
          "iopub.status.busy": "2025-09-26T09:06:05.106419Z",
          "iopub.status.idle": "2025-09-26T09:06:05.223417Z",
          "shell.execute_reply": "2025-09-26T09:06:05.222070Z",
          "shell.execute_reply.started": "2025-09-26T09:06:05.106690Z"
        },
        "id": "3f30684a-0369-4ac6-ba5f-f8cd2246e532",
        "outputId": "bd040a95-6483-4555-976e-4ac51a11bc90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Query 2: Get Real-Time Record for primary_key = 'Fisherman’s Wharf' ---\n",
            "❌ Query Failed: Record for 'Fisherman’s Wharf' not found. (Check if the key was present in the aggregated data.)\n"
          ]
        }
      ],
      "source": [
        "# Query 2\n",
        "# Query Fisherman's Wharf\n",
        "\n",
        "import time\n",
        "\n",
        "sagemaker_runtime_client = sagemaker_session.boto_session.client('sagemaker-featurestore-runtime', region_name=region)\n",
        "FEATURE_GROUP_NAME = neighborhood_feature_group.name\n",
        "RECORD_IDENTIFIER_FEATURE_NAME = 'primary_key'\n",
        "query_key = \"Fisherman’s Wharf\"\n",
        "\n",
        "print(f\"--- Query 2: Get Real-Time Record for primary_key = '{query_key}' ---\")\n",
        "\n",
        "# Using neighborhood_feature_group.name\n",
        "response = sagemaker_runtime_client.get_record(\n",
        "    FeatureGroupName=neighborhood_feature_group.name,\n",
        "    RecordIdentifierValueAsString=query_key\n",
        ")\n",
        "\n",
        "record = response.get('Record')\n",
        "if record:\n",
        "    print(\"\\n✅ Query Successful! Retrieved Features:\")\n",
        "    for feature in record:\n",
        "        print(f\"  - {feature['FeatureName']}: {feature['ValueAsString']}\")\n",
        "else:\n",
        "    print(f\"❌ Query Failed: Record for '{query_key}' not found. (Check if the key was present in the aggregated data.)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99fa7263-2d8a-4e21-b11e-84aacb4ccb8e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-26T09:06:49.279678Z",
          "iopub.status.busy": "2025-09-26T09:06:49.279399Z",
          "iopub.status.idle": "2025-09-26T09:06:49.382770Z",
          "shell.execute_reply": "2025-09-26T09:06:49.381637Z",
          "shell.execute_reply.started": "2025-09-26T09:06:49.279656Z"
        },
        "id": "99fa7263-2d8a-4e21-b11e-84aacb4ccb8e",
        "outputId": "eff98521-2d3d-4547-97f2-eaccd0ee1985"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Query 3: Get Real-Time Record for primary_key = 'Los Osos' ---\n",
            "\n",
            "✅ Query Successful! Retrieved Features:\n",
            "  - primary_key: Los Osos\n",
            "  - median_house_value: 221612.5\n",
            "  - median_house_age: 11.25\n",
            "  - total_households: 612\n",
            "  - bedrooms_per_household: 1.0478845404823531\n",
            "  - ocean_lt_1h: 0.0\n",
            "  - inland: 0.0\n",
            "  - island: 0.0\n",
            "  - ocean_near_bay: 0.0\n",
            "  - ocean_near_ocean: 1.0\n",
            "  - event_time: 1758876561.0\n"
          ]
        }
      ],
      "source": [
        "# Query 3\n",
        "# Query Los Osos\n",
        "\n",
        "import time\n",
        "\n",
        "sagemaker_runtime_client = sagemaker_session.boto_session.client('sagemaker-featurestore-runtime', region_name=region)\n",
        "FEATURE_GROUP_NAME = neighborhood_feature_group.name\n",
        "RECORD_IDENTIFIER_FEATURE_NAME = 'primary_key'\n",
        "query_key = \"Los Osos\"\n",
        "\n",
        "print(f\"--- Query 3: Get Real-Time Record for primary_key = '{query_key}' ---\")\n",
        "\n",
        "response = sagemaker_runtime_client.get_record(\n",
        "    FeatureGroupName=neighborhood_feature_group.name,\n",
        "    RecordIdentifierValueAsString=query_key\n",
        ")\n",
        "\n",
        "record = response.get('Record')\n",
        "if record:\n",
        "    print(\"\\n✅ Query Successful! Retrieved Features:\")\n",
        "    for feature in record:\n",
        "        print(f\"  - {feature['FeatureName']}: {feature['ValueAsString']}\")\n",
        "else:\n",
        "    print(f\"❌ Query Failed: Record for '{query_key}' not found. (Check if the key was present in the aggregated data.)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9770dc73-6cdb-49b4-a42f-0189e7c028e1",
      "metadata": {
        "id": "9770dc73-6cdb-49b4-a42f-0189e7c028e1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}