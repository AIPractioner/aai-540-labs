{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-05T05:36:24.829267Z",
     "iopub.status.busy": "2025-10-05T05:36:24.828989Z",
     "iopub.status.idle": "2025-10-05T05:36:25.144543Z",
     "shell.execute_reply": "2025-10-05T05:36:25.143774Z",
     "shell.execute_reply.started": "2025-10-05T05:36:24.829245Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "com.fasterxml.jackson.core.JsonParseException: Unexpected character ('━' (code 9473 / 0x2501)): expected a valid value (JSON String, Number, Array, Object or token 'null', 'true' or 'false')\n",
      " at [Source: (String)\"     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.5/1.5 MB 50.9 MB/s eta 0:00:00\"; line: 1, column: 7]\n"
     ]
    }
   ],
   "source": [
    "# Matt Thompson\n",
    "# AAI 540 \n",
    "# Assignment 5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-05T05:36:22.982963Z",
     "iopub.status.idle": "2025-10-05T05:36:22.983451Z",
     "shell.execute_reply": "2025-10-05T05:36:22.983289Z",
     "shell.execute_reply.started": "2025-10-05T05:36:22.983272Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# This attempts to install sagemaker into the current environment\n",
    "print(\"Starting SageMaker SDK installation...\")\n",
    "# The following command is often robust to write restrictions\n",
    "try:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"sagemaker\", \"--user\"])\n",
    "    print(\"Installation attempt complete. Please RESTART YOUR KERNEL NOW.\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Installation failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-05T05:36:22.981082Z",
     "iopub.status.idle": "2025-10-05T05:36:22.981363Z",
     "shell.execute_reply": "2025-10-05T05:36:22.981243Z",
     "shell.execute_reply.started": "2025-10-05T05:36:22.981231Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "!pip install sagemaker\n",
    "\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import boto3\n",
    "from time import sleep\n",
    "from threading import Thread\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role, session, Session, image_uris\n",
    "from sagemaker.s3 import S3Downloader, S3Uploader\n",
    "from sagemaker.processing import ProcessingJob\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Execution role\n",
    "role = get_execution_role()\n",
    "print(\"RoleArn:\", role)\n",
    "region = session.boto_region_name\n",
    "print(\"Region:\", region)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup S3 bucket\n",
    "# This is the bucket into which the data is captured\n",
    "bucket = session.default_bucket()\n",
    "print(\"Demo Bucket:\", bucket)\n",
    "\n",
    "prefix = \"sagemaker/Churn-ModelBiasMonitor-20201201\" # Changed prefix name for clarity\n",
    "\n",
    "## S3 prefixes\n",
    "data_capture_prefix = f\"{prefix}/datacapture\"\n",
    "s3_capture_upload_path = f\"s3://{bucket}/{data_capture_prefix}\"\n",
    "\n",
    "# Ground truth path (reused for both Model Quality and Bias)\n",
    "ground_truth_upload_path = (\n",
    "    f\"s3://{bucket}/{prefix}/ground_truth_data/{datetime.now():%Y-%m-%d-%H-%M-%S}\"\n",
    ")\n",
    "\n",
    "# New prefixes for Model BIAS baseline and reports\n",
    "bias_baseline_prefix = prefix + \"/bias_baselining\"\n",
    "bias_baseline_data_prefix = bias_baseline_prefix + \"/data\"\n",
    "bias_baseline_results_prefix = bias_baseline_prefix + \"/results\"\n",
    "bias_baseline_data_uri = f\"s3://{bucket}/{bias_baseline_data_prefix}\"\n",
    "bias_baseline_results_uri = f\"s3://{bucket}/{bias_baseline_results_prefix}\"\n",
    "\n",
    "\n",
    "## Get the model monitor image\n",
    "monitor_image_uri = image_uris.retrieve(framework=\"model-monitor\", region=region)\n",
    "print(\"Image URI:\", monitor_image_uri)\n",
    "print(f\"Capture path: {s3_capture_upload_path}\")\n",
    "print(f\"Ground truth path: {ground_truth_upload_path}\")\n",
    "print(f\"Bias Report path: {bias_baseline_results_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload some test files\n",
    "S3Uploader.upload(\"test_data/upload-test-file.txt\", f\"s3://{bucket}/test_upload\")\n",
    "print(\"Success! You are all set to proceed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Upload the pretrained model to S3\n",
    "s3_key = f\"s3://{bucket}/{prefix}\"\n",
    "model_url = S3Uploader.upload(\"model/xgb-churn-prediction-model.tar.gz\", s3_key)\n",
    "model_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f\"DEMO-xgb-churn-pred-model-monitor-{datetime.utcnow():%Y-%m-%d-%H%M}\"\n",
    "image_uri = image_uris.retrieve(framework=\"xgboost\", version=\"0.90-1\", region=region)\n",
    "model = Model(image_uri=image_uri, model_data=model_url, role=role, sagemaker_session=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = f\"DEMO-xgb-churn-model-bias-monitor-{datetime.utcnow():%Y-%m-%d-%H%M}\"\n",
    "print(\"EndpointName =\", endpoint_name)\n",
    "\n",
    "# Set sampling_percentage to 100 to capture all data for monitoring\n",
    "data_capture_config = DataCaptureConfig(\n",
    "    enable_capture=True, sampling_percentage=100, destination_s3_uri=s3_capture_upload_path\n",
    ")\n",
    "\n",
    "model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    endpoint_name=endpoint_name,\n",
    "    data_capture_config=data_capture_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name, sagemaker_session=session, serializer=CSVSerializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 3 mark down goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import ModelBiasMonitor, BiasAnalysisConfig\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "\n",
    "# --- 3.1 & 3.2 Execute predictions and create Bias Baseline Dataset ---\n",
    "\n",
    "# Assume the facet/sensitive attribute is 'SeniorCitizen' which is the 19th column (index 19)\n",
    "# in the input features of the original validation.csv.\n",
    "churn_cutoff = 0.8\n",
    "validate_dataset_bias = \"validation_with_predictions_and_bias_feature.csv\"\n",
    "sensitive_feature_index = 19  # Example: Index of the sensitive feature in the full input data\n",
    "sensitive_feature_name = \"SeniorCitizen\"\n",
    "limit = 200 # Limit to a small set for quick baselining\n",
    "\n",
    "i = 0\n",
    "with open(f\"test_data/{validate_dataset_bias}\", \"w\") as baseline_file:\n",
    "    # Header: probability, prediction, label, sensitive_feature\n",
    "    baseline_file.write(f\"probability,prediction,label,{sensitive_feature_name}\\n\")\n",
    "    with open(\"test_data/validation.csv\", \"r\") as f:\n",
    "        # Skip header if it exists, otherwise assume no header as in the original template\n",
    "        \n",
    "        for row in f:\n",
    "            (label, input_cols) = row.split(\",\", 1)\n",
    "            \n",
    "            # The input_cols are the features (19 of them).\n",
    "            # The sensitive feature is the last one (index 18 in input_cols split)\n",
    "            input_features = input_cols.strip().split(\",\")\n",
    "            if len(input_features) < sensitive_feature_index:\n",
    "                 # Skip if the row doesn't have enough features (e.g., if there's a header)\n",
    "                 continue\n",
    "            \n",
    "            sensitive_feature_value = input_features[sensitive_feature_index - 1] \n",
    "            \n",
    "            try:\n",
    "                probability = float(predictor.predict(input_cols))\n",
    "            except Exception as e:\n",
    "                # Handle potential prediction error or empty line\n",
    "                print(f\"Error predicting: {e}\")\n",
    "                continue\n",
    "                \n",
    "            prediction = \"1\" if probability > churn_cutoff else \"0\"\n",
    "            \n",
    "            # Write prediction, label, and sensitive feature to the baseline file\n",
    "            baseline_file.write(f\"{probability},{prediction},{label},{sensitive_feature_value}\\n\")\n",
    "            i += 1\n",
    "            if i > limit:\n",
    "                break\n",
    "            # print(\".\", end=\"\", flush=True) # Commenting out to keep output clean\n",
    "            sleep(0.01) # Reduced sleep time\n",
    "print(\"Done creating Bias Baseline Dataset!\")\n",
    "\n",
    "\n",
    "# --- 3.3 Upload the predictions as a bias baseline dataset ---\n",
    "baseline_dataset_bias_uri = S3Uploader.upload(\n",
    "    f\"test_data/{validate_dataset_bias}\", bias_baseline_data_uri\n",
    ")\n",
    "print(f\"Uploaded Bias Baseline Data: {baseline_dataset_bias_uri}\")\n",
    "\n",
    "\n",
    "# --- 3.4 Define Bias Analysis Configuration and Execute Baseling Job ---\n",
    "# Define the configuration for the bias analysis\n",
    "bias_analysis_config = BiasAnalysisConfig(\n",
    "    model_predicted_label=\"prediction\",\n",
    "    model_scores=\"probability\",\n",
    "    problem_type=\"BinaryClassification\",\n",
    "    ground_truth_attribute=\"label\",\n",
    "    problem_type_config={\n",
    "        \"label_values_or_threshold\": [\"1\"] # positive label value is '1'\n",
    "    },\n",
    "    facet_attribute=[sensitive_feature_name], # The sensitive feature column name\n",
    "    facet_attribute_type=\"categorical\",\n",
    "    group_of_interest=[\"1\"], # The value in the facet_attribute that is the group of interest (e.g., senior citizen is marked as '1')\n",
    "    positive_label=[\"1\"] # The value of the label that is the positive outcome (churn)\n",
    ")\n",
    "\n",
    "# Create the Model Bias Monitoring Object\n",
    "churn_model_bias_monitor = ModelBiasMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=1800,\n",
    "    sagemaker_session=session,\n",
    ")\n",
    "\n",
    "# Name and Execute the Baseline Suggestion Job for Bias\n",
    "bias_baseline_job_name = f\"DEMO-xgb-churn-bias-baseline-job-{datetime.utcnow():%Y-%m-%d-%H%M}\"\n",
    "\n",
    "print(f\"Starting Bias Baseline Job: {bias_baseline_job_name}\")\n",
    "\n",
    "bias_job = churn_model_bias_monitor.suggest_baseline(\n",
    "    job_name=bias_baseline_job_name,\n",
    "    baseline_dataset=baseline_dataset_bias_uri,\n",
    "    dataset_format=DatasetFormat.csv(header=True),\n",
    "    output_s3_uri=bias_baseline_results_uri,\n",
    "    bias_analysis_config=bias_analysis_config,\n",
    ")\n",
    "\n",
    "bias_job.wait(logs=False)\n",
    "print(\"Bias Baseline Job finished.\")\n",
    "\n",
    "\n",
    "# --- 3.5 Explore the results of the baselining job ---\n",
    "bias_baseline_job = churn_model_bias_monitor.latest_baselining_job\n",
    "\n",
    "print(\"--- Bias Baseline Statistics (Disparate Impact) ---\")\n",
    "# Example of retrieving a specific bias metric\n",
    "di_post_training = bias_baseline_job.baseline_statistics().body_dict[\"post_training_bias_metrics\"][\"disparate_impact\"][\"value\"]\n",
    "print(f\"Post-training Disparate Impact (DI): {di_post_training}\")\n",
    "# A DI value significantly less than 0.8 or greater than 1.25 may indicate bias.\n",
    "\n",
    "print(\"\\n--- Bias Constraints ---\")\n",
    "bias_constraints_df = pd.DataFrame(bias_baseline_job.suggested_constraints().body_dict[\"bias_constraints\"])\n",
    "print(bias_constraints_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# section 4 markdown goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4.1 Generate prediction data for Model Bias Monitoring ---\n",
    "# This part starts the thread to send traffic to the endpoint.\n",
    "def invoke_endpoint(ep_name, file_name):\n",
    "    with open(file_name, \"r\") as f:\n",
    "        i = 0\n",
    "        for row in f:\n",
    "            payload = row.rstrip(\"\\n\")\n",
    "            response = session.sagemaker_runtime_client.invoke_endpoint(\n",
    "                EndpointName=endpoint_name,\n",
    "                ContentType=\"text/csv\",\n",
    "                Body=payload,\n",
    "                InferenceId=str(i),  # unique ID per row\n",
    "            )[\"Body\"].read()\n",
    "            i += 1\n",
    "            sleep(0.5) # Reduced sleep time\n",
    "            \n",
    "def invoke_endpoint_forever():\n",
    "    while True:\n",
    "        try:\n",
    "            # We use the original validation data input features to invoke the endpoint\n",
    "            invoke_endpoint(endpoint_name, \"test_data/test-dataset-input-cols.csv\")\n",
    "        except session.sagemaker_runtime_client.exceptions.ValidationError:\n",
    "            pass\n",
    "        except Exception:\n",
    "             pass\n",
    "\n",
    "thread = Thread(target=invoke_endpoint_forever)\n",
    "thread.start()\n",
    "print(\"Inference traffic thread started.\")\n",
    "\n",
    "\n",
    "# --- 4.2 View captured data (optional but good practice) ---\n",
    "print(\"Waiting for captures to show up\", end=\"\")\n",
    "for _ in range(30): # Reduced wait time\n",
    "    capture_files = sorted(S3Downloader.list(f\"{s3_capture_upload_path}/{endpoint_name}\"))\n",
    "    if capture_files:\n",
    "        print(\"\\nFound Capture Files:\")\n",
    "        print(\"\\n \".join(capture_files[-1:]))\n",
    "        break\n",
    "    print(\".\", end=\"\", flush=True)\n",
    "    sleep(1)\n",
    "print()\n",
    "\n",
    "\n",
    "# --- 4.3 Generate synthetic ground truth ---\n",
    "# This part starts the thread to upload ground truth data.\n",
    "import random\n",
    "\n",
    "def ground_truth_with_id(inference_id):\n",
    "    random.seed(inference_id)  # to get consistent results\n",
    "    rand = random.random()\n",
    "    return {\n",
    "        \"groundTruthData\": {\n",
    "            \"data\": \"1\" if rand < 0.7 else \"0\",  # randomly generate positive labels 70% of the time\n",
    "            \"encoding\": \"CSV\",\n",
    "        },\n",
    "        \"eventMetadata\": {\n",
    "            \"eventId\": str(inference_id),\n",
    "        },\n",
    "        \"eventVersion\": \"0\",\n",
    "    }\n",
    "\n",
    "def upload_ground_truth(records, upload_time):\n",
    "    fake_records = [json.dumps(r) for r in records]\n",
    "    data_to_upload = \"\\n\".join(fake_records)\n",
    "    target_s3_uri = f\"{ground_truth_upload_path}/{upload_time:%Y/%m/%d/%H/%M%S}.jsonl\"\n",
    "    S3Uploader.upload_string_as_file_body(data_to_upload, target_s3_uri)\n",
    "\n",
    "NUM_GROUND_TRUTH_RECORDS = 334 \n",
    "\n",
    "def generate_fake_ground_truth_forever():\n",
    "    j = 0\n",
    "    while True:\n",
    "        fake_records = [ground_truth_with_id(i) for i in range(NUM_GROUND_TRUTH_RECORDS)]\n",
    "        upload_ground_truth(fake_records, datetime.utcnow())\n",
    "        j = (j + 1) % 5\n",
    "        sleep(60 * 60)  # do this once an hour\n",
    "\n",
    "gt_thread = Thread(target=generate_fake_ground_truth_forever)\n",
    "gt_thread.start()\n",
    "print(\"Ground truth generation thread started.\")\n",
    "\n",
    "\n",
    "# --- 4.4 Create a bias monitoring schedule ---\n",
    "from sagemaker.model_monitor import CronExpressionGenerator\n",
    "from sagemaker.model_monitor import EndpointInput\n",
    "\n",
    "## Monitoring schedule name\n",
    "churn_bias_monitor_schedule_name = (\n",
    "    f\"DEMO-xgb-churn-bias-monitoring-schedule-{datetime.utcnow():%Y-%m-%d-%H%M}\")\n",
    "\n",
    "# Create an enpointInput for Bias Monitor\n",
    "# The bias monitor needs to inspect the captured data for features and predictions.\n",
    "# We don't need probability_attribute/threshold here, as bias analysis is done on the full captured data and ground truth.\n",
    "endpointInput_bias = EndpointInput(\n",
    "    endpoint_name=predictor.endpoint_name,\n",
    "    destination=\"/opt/ml/processing/input_data\",\n",
    ")\n",
    "\n",
    "# The data_input parameter is the location of the raw inference request data, which is where the facet data (SeniorCitizen) is.\n",
    "data_input = f\"s3://{bucket}/{data_capture_prefix}/{endpoint_name}\"\n",
    "\n",
    "\n",
    "print(f\"Creating Bias Monitoring Schedule: {churn_bias_monitor_schedule_name}\")\n",
    "\n",
    "response_bias = churn_model_bias_monitor.create_monitoring_schedule(\n",
    "    monitor_schedule_name=churn_bias_monitor_schedule_name,\n",
    "    endpoint_input=endpointInput_bias,\n",
    "    data_input=data_input,\n",
    "    output_s3_uri=bias_baseline_results_uri,\n",
    "    ground_truth_input=ground_truth_upload_path,\n",
    "    constraints=bias_baseline_job.suggested_constraints(),\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly(),\n",
    "    enable_cloudwatch_metrics=True,\n",
    "    bias_analysis_config=bias_analysis_config,\n",
    ")\n",
    "\n",
    "\n",
    "# --- 4.5 Examine monitoring schedule executions (Wait for first execution) ---\n",
    "print(\"Waiting for first execution of Bias Monitor\", end=\"\")\n",
    "bias_execution = None\n",
    "while True:\n",
    "    bias_execution = churn_model_bias_monitor.describe_schedule().get(\n",
    "        \"LastMonitoringExecutionSummary\"\n",
    "    )\n",
    "    if bias_execution:\n",
    "        break\n",
    "    print(\".\", end=\"\", flush=True)\n",
    "    sleep(10)\n",
    "print(\"\\nBias Execution found! Status:\", bias_execution['MonitoringExecutionStatus'])\n",
    "\n",
    "# Get all executions\n",
    "bias_executions = churn_model_bias_monitor.list_executions()\n",
    "\n",
    "while not bias_executions:\n",
    "    bias_executions = churn_model_bias_monitor.list_executions()\n",
    "    print(\".\", end=\"\", flush=True)\n",
    "    sleep(10)\n",
    "\n",
    "latest_bias_execution = bias_executions[-1]\n",
    "\n",
    "status = bias_execution[\"MonitoringExecutionStatus\"]\n",
    "while status in [\"Pending\", \"InProgress\"]:\n",
    "    print(\"Waiting for execution to finish\", end=\"\")\n",
    "    latest_bias_execution.wait(logs=False)\n",
    "    latest_job = latest_bias_execution.describe()\n",
    "    print()\n",
    "    print(f\"{latest_job['ProcessingJobName']} job status:\", latest_job[\"ProcessingJobStatus\"])\n",
    "    # Wait for the next stage if it's a multi-stage job\n",
    "    sleep(30)\n",
    "    latest_bias_execution = churn_model_bias_monitor.list_executions()[-1]\n",
    "    bias_execution = churn_model_bias_monitor.describe_schedule()[\"LastMonitoringExecutionSummary\"]\n",
    "    status = bias_execution[\"MonitoringExecutionStatus\"]\n",
    "\n",
    "print(\"Bias Execution status is:\", status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# section 5 markdown goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5.1 View violations generated by monitoring schedule ---\n",
    "latest_bias_execution = churn_model_bias_monitor.list_executions()[-1]\n",
    "report_uri = latest_bias_execution.describe()[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    "print(\"Bias Report Uri:\", report_uri)\n",
    "\n",
    "pd.options.display.max_colwidth = None\n",
    "try:\n",
    "    bias_violations = latest_bias_execution.constraint_violations().body_dict[\"violations\"]\n",
    "    bias_violations_df = pd.json_normalize(bias_violations)\n",
    "    print(\"\\n--- Model Bias Constraint Violations ---\")\n",
    "    print(bias_violations_df.head(10))\n",
    "except Exception as e:\n",
    "    print(f\"No bias violations found yet or error accessing violations: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup markdown goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Clean up resources (optional) ---\n",
    "# Stop the threads (note: this may not always work perfectly in a notebook environment, manual kernel restart may be needed)\n",
    "thread.join(timeout=1)\n",
    "gt_thread.join(timeout=1)\n",
    "\n",
    "# Delete the endpoint and model\n",
    "predictor.delete_endpoint()\n",
    "model.delete_model()\n",
    "\n",
    "# Delete the monitoring schedules\n",
    "churn_model_bias_monitor.delete_schedule()\n",
    "\n",
    "# Delete the CloudWatch Alarm (if one were created specifically for bias)\n",
    "# For simplicity, no specific CW alarm cell was added for bias, but it would go here.\n",
    "\n",
    "print(\"Cleanup complete.\")"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Glue PySpark",
   "language": "python",
   "name": "glue_pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "Python_Glue_Session",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
